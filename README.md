# TinyGPT

## A lightweight deep language model

![image](https://github.com/jessiepathfinder/TinyGPT/assets/55774978/47448f3f-65c8-4088-910e-d31701296108)

## Current model architecture
![image](https://github.com/jessiepathfinder/TinyGPT/assets/55774978/1f5c0f59-e8ff-4400-9332-205daa759547)


### Notes
1. TinyGPT's norm uses group norm instead of layer norm
2. TinyGPT's multi-head attention shares the same key over all heads
3. TinyGPT uses 10 attention heads
4. All Conv1D layers are causal conv



[pre-trained model (3072 batches)](https://www.mediafire.com/file/5f1ld5r2yqnsdsg/TinyGPT.Pretrained.7z/file)
